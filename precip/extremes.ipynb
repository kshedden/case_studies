{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analysis of precipitation data using extreme value methods\n",
    "\n",
    "This notebook demonstrates several methods for assessing the frequency of extreme precipitation events.\n",
    "\n",
    "It is important to remember that when we are studying extreme events using statistical analysis, we are not aiming to classify individual events as being extreme or non-extreme.  Instead, we are aiming to characterize the tail of the probability distribution of event sizes.  This reveals the long-run propensity to produce very large events, and determines statistical properties such as the frequencies of records (the largest value yet seen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genpareto, genextreme\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma\n",
    "from pathlib import Path\n",
    "import lmom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Below we define several functions that implement methods for extreme value analysis.  After defining these functions, we can use them to analyze the precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tail_shape(z, p0=0.1, family=\"powerlaw\"):\n",
    "    \"\"\"\n",
    "    Returns values x, p such that the slope of p on x estimates the\n",
    "    shape parameter (tail index) of a distribution with power-law\n",
    "    tails (if family='powerlaw'), or the rate parameter of a\n",
    "    distribution with exponential tails (if family='exponential').\n",
    "    The upper p0 fraction of the data in z are used to produce (x, p).\n",
    "    The returned values in x are the order statistics of z in the\n",
    "    exponential case, and the log order statistics of z in the powerlaw\n",
    "    case. The returned values in p are derived from probability\n",
    "    points.  Scatterplot p against x to get a visualization of the\n",
    "    tail shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if family not in [\"exponential\", \"powerlaw\"]:\n",
    "        raise ValueError(\"Unknown family %s\" % family)\n",
    "\n",
    "    z = z.copy()\n",
    "    p = 1 - p0\n",
    "    z = np.asarray(z)\n",
    "    z.sort()\n",
    "    n = len(z)\n",
    "    m = int(np.around(p*n))\n",
    "    x = z[m-1:]\n",
    "    if family == \"powerlaw\":\n",
    "        x = np.log(x + 1e-6)\n",
    "    p = np.log(1 - np.arange(m, n+1) / (n+1))\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_tail_reg(x, ax, p0=0.99, family=\"powerlaw\"):\n",
    "    \"\"\"\n",
    "    Use least squares regression in the upper 'p0' fraction of the right\n",
    "    tail of a quantile plot to estimate the shape parameter, and add the\n",
    "    best fit line to the plot in axes 'ax'.\n",
    "    \"\"\"\n",
    "\n",
    "    x, p = tail_shape(x, p0=p0, family=family)\n",
    "\n",
    "    ax.plot(x, p, color=\"orange\")\n",
    "\n",
    "    # Estimate the tail index using a least squares fit to the order\n",
    "    # statistics.\n",
    "    alpha_hat = -np.cov(p, x)[0, 1] / np.var(x)\n",
    "    icept = p.mean() + alpha_hat*x.mean()\n",
    "\n",
    "    # The coordinates of the best-fit line\n",
    "    xx = np.asarray([x.min(), x.max()])\n",
    "    yy = icept - alpha_hat*xx\n",
    "\n",
    "    ax.plot(xx, yy, color=\"purple\")\n",
    "\n",
    "    return icept, alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def hill(z, k=200):\n",
    "    \"\"\"\n",
    "    Estimate the tail index of a distribution with poower law tails using Hill's\n",
    "    estimator, based on the upper k order statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.sort(z)\n",
    "    z = np.log(z[-k:])\n",
    "    return 1 / (z[1:] - z[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_hill(z):\n",
    "    \"\"\"\n",
    "    Plot the Hill estimate of the tail index for a range\n",
    "    of values of the tuning parameter k.\n",
    "    \"\"\"\n",
    "\n",
    "    kv = np.arange(20, 501, 5)\n",
    "    ta = np.asarray([hill(z, k=k) for k in kv])\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.set_title(\"Hill estimate of the tail index\")\n",
    "    ax.plot(kv, ta)\n",
    "    ax.set_xlabel(\"k\", size=16)\n",
    "    ax.set_ylabel(\"Tail index estimate\", size=16)\n",
    "    ax.set_ylim(2.5, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_gev(x):\n",
    "    \"\"\"\n",
    "    Fit a generalized extreme value distribution (GEV) using maximum likelihood\n",
    "    estimation to the data in 'x'. Probability weighted moments are used to obtain\n",
    "    starting values:\n",
    "    https://www.stat.cmu.edu/technometrics/80-89/VOL-27-03/v2703251.pdf\n",
    "    \n",
    "    The returned frozen GEV distribution follows the scipy parameterization:\n",
    "    \n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genextreme.html\n",
    "    \n",
    "    Note that this differs from another common parameterization, which is the one\n",
    "    used on Wikipedia:\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "\n",
    "    # Plotting positions\n",
    "    pp = np.arange(1/2, n + 1/2) / n\n",
    "\n",
    "    # Calculate the first three probability weighted moments\n",
    "    b = np.zeros(3)\n",
    "    for r in range(3):\n",
    "        b[r] = np.dot(pp**r, x) / n\n",
    "\n",
    "    # The PWM estimator of Hoskins et al.\n",
    "    c = (2*b[1] - b[0]) / (3*b[2] - b[0])  - np.log(2) / np.log(3)\n",
    "    shape = 7.8590*c + 2.9554*c**2\n",
    "    scale = (2*b[1] - b[0]) * shape / (gamma(1 + shape) * (1 - 1/2**shape))\n",
    "    loc = b[0] + scale*(gamma(1 + shape) - 1) / shape\n",
    "    ge = genextreme(shape, loc=loc, scale=scale)\n",
    "    \n",
    "    # Get the MLE\n",
    "    def f(par):\n",
    "        shape, loc, logscale = par\n",
    "        d = genextreme(shape, loc=loc, scale=np.exp(logscale))\n",
    "        return -d.logpdf(x).sum()\n",
    "\n",
    "    logscale = np.log(scale)\n",
    "    x0 = np.asarray([shape, loc, logscale])\n",
    "    rr = minimize(f, x0, method=\"powell\")\n",
    "    shape, loc, logscale = rr.x\n",
    "    ge = genextreme(shape, loc=loc, scale=np.exp(logscale))\n",
    "    return ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def block_max(dx):\n",
    "    \"\"\"\n",
    "    Calculate the maximum precipitation value for each complete year,\n",
    "    and fit a generalized extreme value (GEV) distribution to the\n",
    "    data.  Then use the fitted model to calculate returns for a sequence\n",
    "    of time horizons, and create a QQ plot to assess goodness-of-fit.\n",
    "    \n",
    "    Returns the fitted generalized extreme value distribution model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the annual maximum for all complete years\n",
    "    dx = dx.query(\"year > 1958 & year < 2023\")\n",
    "    yrmx = dx.groupby(\"year\")[\"PRCP\"].agg(np.max)\n",
    "    \n",
    "    # Fit a generalized extreme value distribution to the block maxima.\n",
    "    gev = fit_gev(yrmx)\n",
    "\n",
    "    # m-observation returns\n",
    "    rr = pd.DataFrame({\"Years\": [10, 100, 500, 1000]})\n",
    "    rr[\"Return\"] = gev.ppf(1 - 1/rr.Years)\n",
    "    print(rr)\n",
    "\n",
    "    # Make a QQ plot to assess goodness of fit of the GEV model\n",
    "    z = np.sort(yrmx)\n",
    "    n = len(z)\n",
    "    pp = np.arange(1, n + 1) / (n + 1)\n",
    "    qq = gev.ppf(pp)\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.plot(qq, z)\n",
    "    ax.set_xlabel(\"GEV quantiles\")\n",
    "    ax.set_ylabel(\"Order statistics\")\n",
    "    ax.set_title(\"GEV fit to annual maxima\")\n",
    "    plt.show()\n",
    "\n",
    "    return gev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def gp_estimate(z):\n",
    "    \"\"\"\n",
    "    Estimate the parameters of a generalized Pareto distribution\n",
    "    using the empirical Bayes method of Zhang and Stephens.\n",
    "    https://www.jstor.org/stable/pdf/40586625.pdf\n",
    "    \n",
    "    Returns the fitted generalized Pareto model. See the link below for\n",
    "    details about how the distribution is parameterized:\n",
    "    \n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genpareto.html\n",
    "    \"\"\"\n",
    "\n",
    "    # The prior is discrete and data-adaptive, based on these parameters\n",
    "    z = np.sort(z)\n",
    "    n = len(z)\n",
    "    xstar = z[int(np.round(n/4 + 0.5))]\n",
    "    m = np.ceil(20 + np.sqrt(n))\n",
    "    xmax = z.max()\n",
    "\n",
    "    # The grid on which the prior is supported\n",
    "    jj = np.arange(1, m+1)\n",
    "    tgrid = 1/xmax + (1 - np.sqrt(m/(jj-0.5))) / (3 * xstar)\n",
    "\n",
    "    # The profile log likelihood function\n",
    "    def profile(theta):\n",
    "        k = -np.log(1 - theta*z).mean()\n",
    "        return n*(np.log(theta/k) + k - 1)\n",
    "\n",
    "    # The posterior distribution\n",
    "    ltg = np.asarray([profile(t) for t in tgrid])\n",
    "    ltg -= ltg.max()\n",
    "    Ltg = np.exp(ltg)\n",
    "    Ltg /= Ltg.sum()\n",
    "    \n",
    "    # The posterior is a generalized Pareto with these parameters\n",
    "    theta_hat = np.dot(Ltg, tgrid)\n",
    "    k_hat = -np.log(1 - theta_hat*z).mean()\n",
    "    scale_hat = k_hat / theta_hat\n",
    "\n",
    "    # Return the posterior distribution\n",
    "    return genpareto(-k_hat, scale=scale_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eb_analysis(z, thresh):\n",
    "    \"\"\"\n",
    "    Fit a generalized Pareto model to the exceedances derived from z,\n",
    "    using empirical Bayes estimation, and create a QQ plot to assess\n",
    "    the goodness-of-fit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Exceedances\n",
    "    z = z[z > thresh] - thresh\n",
    "\n",
    "    # Empirical Bayes estimate of Zhang and Stephens.\n",
    "    eb = gp_estimate(z)\n",
    "\n",
    "    n = len(z)\n",
    "    pp = np.linspace(1/2, n - 1/2, n) / n # plotting positions\n",
    "    qq = eb.ppf(pp)\n",
    "    z = np.sort(z)\n",
    "\n",
    "    # QQ plot to show goodness of fit\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.set_title(\"EB: shape=%.3f scale=%.3f, tail=%.2f\" % (eb.args[0], eb.kwds[\"scale\"], 1/eb.args[0]))\n",
    "    ax.plot(qq, z)\n",
    "    plt.xlabel(\"GP quantiles (EB)\", size=16)\n",
    "    plt.ylabel(\"Order statistics\", size=16)\n",
    "    plt.show()\n",
    "\n",
    "    return eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_tails(z, p0, thresh, family):\n",
    "    \"\"\"\n",
    "    Plot the tail of the estimated CDF based on the upper 'p0' proportion of the data in z.  \n",
    "    If family is 'exponential' use a semi-log plot, if family is 'powerlaw' use a log/log plot.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # The number of selected observations\n",
    "    m = int(np.around(p0*n))\n",
    "\n",
    "    xlabel = \"log Q(p)\" if family == \"powerlaw\" else \"Q(p)\"\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    icept, alpha = fit_tail_reg(z, ax, p0=p0, family=family)\n",
    "    ax.set_xlabel(xlabel, size=16)\n",
    "    ax.set_ylabel(\"log(1-p)\", size=16)\n",
    "    ti = \"%s model, threshold=%.1f, top %.1f%% (n=%d), alpha=%.3f\" %\\\n",
    "           (family.title(), thresh, 100*p0, m, alpha)\n",
    "    plt.title(ti)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def check_gp_estimate(shape, scale, thresh, n=100000):\n",
    "    z = genpareto.rvs(shape, scale=scale, size=n)\n",
    "    z = z[z > thresh] - thresh\n",
    "    eb = gp_estimate(z)\n",
    "    return eb, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mobs_return(z, mr, thresh, family=\"exponential\", gp=None):\n",
    "    \"\"\"\n",
    "    Calculate the m-observation returns for the data in z, using either\n",
    "    an exponential or generalized Pareto model.\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.asarray(z)\n",
    "    n = len(z)\n",
    "\n",
    "    # Select only extreme values and translate back to the origin\n",
    "    ix = np.flatnonzero(z >= thresh)\n",
    "    q = len(ix) / n # proportion of values exceeding the threshold\n",
    "    z = z[ix]\n",
    "    z -= thresh\n",
    "\n",
    "    pr = 1 - 1 / (q * mr)\n",
    "\n",
    "    if family == \"exponential\":\n",
    "        mn = z.mean()\n",
    "        print(\"Mean = %.2f\" % mn)\n",
    "        m0 = thresh - mn*np.log(1 - pr)\n",
    "    elif family == \"generalizedpareto\":\n",
    "        print(\"Shape=%.2f\" % eb.args[0])\n",
    "        print(\"Scale=%.2f\" % eb.kwds[\"scale\"])\n",
    "        m0 = thresh + gp.ppf(pr)\n",
    "    else:\n",
    "        raise ValueError(\"!!\")\n",
    "\n",
    "    return m0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Change this to point to the location of the data, matching the path name in get_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = Path(\"/home/kshedden/data/Teaching/precip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Choose a specific location to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"USW00094847.csv\" # Detroit\n",
    "#fname = \"USW00012839.csv\" # Miami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(target_dir / (\"%s.gz\" % fname), parse_dates=[\"DATE\"],\n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We only care about these two variables, which must not be missing.  \"PRCP\" is the 24-hour rainfall total, recorded in tenths of a millimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"DATE\", \"PRCP\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Add a year variable for block-maxima (GEV) analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df[\"DATE\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Convert precipitation to millimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PRCP\"] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The data may be sorted already, but sort again just to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Display the first few rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Use this threshold (units are mm) for calculating exceedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 10.0\n",
    "(df[\"PRCP\"] >= thresh).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Plot the data as a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.plot(df[\"DATE\"], df[\"PRCP\"], \"-\", alpha=0.5)\n",
    "plt.xlabel(\"Date\", size=15)\n",
    "plt.ylabel(\"Precipitation (mm)\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Plot the data as a histogram.  A histogram is not useful for studying extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.hist(df[\"PRCP\"])\n",
    "plt.xlabel(\"Precipitation (mm)\", size=13)\n",
    "plt.ylabel(\"Frequency\", size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Plot the data as an (empirical) CDF.  This is not a very helpful approach for judging the structure of the tail of a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "x = np.sort(df[\"PRCP\"])\n",
    "p = np.linspace(0, 1, len(x))\n",
    "plt.plot(x, p, \"-\")\n",
    "plt.xlabel(\"Precipitation (mm)\", size=15)\n",
    "plt.ylabel(\"Cumulative probability\", size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Plot the data as an (empirical) complementary CDF (also known as the ccdf or survival function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "x = np.sort(df[\"PRCP\"])\n",
    "p = np.linspace(0, 1, len(x))\n",
    "plt.plot(x, 1 - p, \"-\")\n",
    "plt.xlabel(\"Precipitation (mm)\", size=15)\n",
    "plt.ylabel(\"Complementary cumulative probability\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Calculate the standardized third and fourth L-moment, compare to figure 3 of [this paper](https://www.tandfonline.com/doi/full/10.1080/00031305.2024.2402898).  Arguably, if the standardized fourth L-moment exceeds 0.35 then conventional statistical inference is \"disrupted\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmom.l3(df[\"PRCP\"]) / lmom.l2(df[\"PRCP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmom.l4(df[\"PRCP\"]) / lmom.l2(df[\"PRCP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "For comparison, below we calculate the standardized third and fourth L-moments for Gaussian (normal) and exponential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e6)\n",
    "\n",
    "z = np.random.normal(size=n)\n",
    "print(lmom.l3(z) / lmom.l2(z))\n",
    "print(lmom.l4(z) / lmom.l2(z))\n",
    "\n",
    "e = -np.log(np.random.uniform(size=n))\n",
    "print(lmom.l3(e) / lmom.l2(e))\n",
    "print(lmom.l4(e) / lmom.l2(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Below we generate probability tail plots, assessing goodness of fit of the upper order statistics to either a powerlaw or exponential pattern.  Various upper fractions of the order statistics are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in [\"powerlaw\", \"exponential\"]:\n",
    "    for p0 in [0.25, 0.1, 0.05, 0.01]:\n",
    "        plot_tails(df[\"PRCP\"], p0, thresh, family)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Below is a \"Hill plot\" suggesting that the distribution might be heavy tailed with a tail index around 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hill(df[\"PRCP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Next we fit generalized extreme value distributions to the block (annual) maxima.  The m-returns based on the GEV model are printed and a qq-plot showing the goodness of fit of the GEV to the data is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gev = block_max(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Below is the shape parameter of the best-fitting GEV to the block maxima.  Due to the parameterization of the GEV used by Scipy, the tail index is -1/shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "gev.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "-1/gev.args[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Fit generalized Pareto models to the exceedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = eb_analysis(df[\"PRCP\"], thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Next we calculate m-observation returns based on an exponential and a generalized Pareto model fit to the 24 hour rainfall totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = np.r_[1, 10, 100, 500, 1000]\n",
    "cfg = [(\"exponential\", None), (\"generalizedpareto\", eb)]\n",
    "for (f,g) in cfg:\n",
    "    print(\"\\nReturns based on %s:\" % f)\n",
    "    mr = mobs_return(df[\"PRCP\"], 365 * yr, thresh, family=f, gp=g)\n",
    "    rr = pd.DataFrame({\"Years\": yr, \"MR\": mr})\n",
    "    print(rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "The cell below is a simple demonstration of how to use the gp_estimate function defined above.  Note that there are different parameterizations of the generalized Pareto distribution (this is true of many probability distributions).  Since we are using [scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genpareto.html), here we use the parameterization adopted by scipy, which is also the parameterization shown on [wikipedia](https://en.wikipedia.org/wiki/Generalized_Pareto_distribution).  The shape parameter $\\xi$ is the reciprocal of the tail index $\\alpha$, i.e. $\\alpha = 1/\\xi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1/3.\n",
    "scale = 1\n",
    "\n",
    "# Generate data and obtain an estimated GPD using the empirical Bayes approach.\n",
    "eb, z = check_gp_estimate(shape=shape, scale=scale, thresh=0)\n",
    "\n",
    "# Check that the population and sample medians match (if they don't something is wrong)\n",
    "print(\"Sample median =\", np.median(z))\n",
    "print(\"Population median =\", scale*(2**shape - 1) / shape)\n",
    "\n",
    "# The fitted GPD has this shape parameter\n",
    "print(\"Fitted GPD shape parameter: \", eb.args)\n",
    "\n",
    "# This is the estimated tail index\n",
    "print(\"Estimated tail index: \", 1 / eb.args[0])\n",
    "print(\"Population tail index: \", 1 / shape)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
