{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analysis of precipitation data using extreme value methods\n",
    "\n",
    "This notebook demonstrates several methods for assessing the frequency of extreme precipitation events.\n",
    "\n",
    "For reference, here is a paper using extreme value techniques to study rainfall in Brazil:\n",
    "\n",
    "https://link.springer.com/article/10.1007/s42452-020-03199-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genpareto, genextreme\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Below we define several functions that implement methods for extreme value analysis.  After defining these functions, we can use them to analyze the precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tail_shape(z, p0=0.1, family=\"powerlaw\"):\n",
    "    \"\"\"\n",
    "    Returns values x, p such that the slope of p on x estimates the\n",
    "    shape parameter (tail index) of a distribution with power-law\n",
    "    tails (if family='powerlaw'), or the rate parameter of a\n",
    "    distribution with exponential tails (if family='exponential').\n",
    "    The upper p0 fraction of the data in z are used to produce (x, p).\n",
    "    The returned values in x are the order statistics of z in the\n",
    "    exponential case, and the log order statistics of z in the powerlaw\n",
    "    case. The returned values in p are derived from probability\n",
    "    points.  Scatterplot p against x to get a visualization of the\n",
    "    tail shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if family not in [\"exponential\", \"powerlaw\"]:\n",
    "        raise ValueError(\"Unknown family %s\" % family)\n",
    "\n",
    "    z = z.copy()\n",
    "    p = 1 - p0\n",
    "    z = np.asarray(z)\n",
    "    z.sort()\n",
    "    n = len(z)\n",
    "    m = int(np.around(p*n))\n",
    "    x = z[m-1:]\n",
    "    if family == \"powerlaw\":\n",
    "        x = np.log(x + 1e-6)\n",
    "    p = np.log(1 - np.arange(m, n+1) / (n+1))\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_tail_reg(x, ax, p0=0.99, family=\"powerlaw\"):\n",
    "    \"\"\"\n",
    "    Use least squares regression in the upper 'p0' fraction of the right\n",
    "    tail of a quantile plot to estimate the shape parameter, and add the\n",
    "    best fit line to the plot in axes 'ax'.\n",
    "    \"\"\"\n",
    "\n",
    "    x, p = tail_shape(x, p0=p0, family=family)\n",
    "\n",
    "    ax.plot(x, p, color=\"orange\")\n",
    "\n",
    "    # Estimate the tail index using a least squares fit to the order\n",
    "    # statistics.\n",
    "    alpha_hat = -np.cov(p, x)[0, 1] / np.var(x)\n",
    "    icept = p.mean() + alpha_hat*x.mean()\n",
    "\n",
    "    # The coordinates of the best-fit line\n",
    "    xx = np.asarray([x.min(), x.max()])\n",
    "    yy = icept - alpha_hat*xx\n",
    "\n",
    "    ax.plot(xx, yy, color=\"purple\")\n",
    "\n",
    "    return icept, alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def hill(z, k=200):\n",
    "    \"\"\"\n",
    "    Estimate the tail index of a distribution with poower law tails using Hill's\n",
    "    estimator, based on the upper k order statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.sort(z)\n",
    "    z = np.log(z[-k:])\n",
    "    return 1 / (z[1:] - z[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_hill(z):\n",
    "    \"\"\"\n",
    "    Plot the Hill estimate of the tail index for a range\n",
    "    of values of the tuning parameter k.\n",
    "    \"\"\"\n",
    "\n",
    "    kv = np.arange(20, 501, 5)\n",
    "    ta = np.asarray([hill(z, k=k) for k in kv])\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.set_title(\"Hill estimate of the tail index\")\n",
    "    ax.plot(kv, ta)\n",
    "    ax.set_xlabel(\"k\", size=16)\n",
    "    ax.set_ylabel(\"Tail index estimate\", size=16)\n",
    "    ax.set_ylim(2.5, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_gev(x):\n",
    "    \"\"\"\n",
    "    Fit a generalized extreme value distribution (GEV) using maximum likelihood\n",
    "    estimation to the data in 'x'. Probability weighted moments are used to obtain\n",
    "    starting values:\n",
    "    https://www.stat.cmu.edu/technometrics/80-89/VOL-27-03/v2703251.pdf\n",
    "    \n",
    "    The returned frozen GEV distribution follows the scipy parameterization:\n",
    "    \n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genextreme.html\n",
    "    \n",
    "    Note that this differs from another common parameterization, which is the one\n",
    "    used on Wikipedia:\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "\n",
    "    # Plotting positions\n",
    "    pp = np.arange(1/2, n + 1/2) / n\n",
    "\n",
    "    # Calculate the first three probability weighted moments\n",
    "    b = np.zeros(3)\n",
    "    for r in range(3):\n",
    "        b[r] = np.dot(pp**r, x) / n\n",
    "\n",
    "    # The PWM estimator of Hoskins et al.\n",
    "    c = (2*b[1] - b[0]) / (3*b[2] - b[0])  - np.log(2) / np.log(3)\n",
    "    shape = 7.8590*c + 2.9554*c**2\n",
    "    scale = (2*b[1] - b[0]) * shape / (gamma(1 + shape) * (1 - 1/2**shape))\n",
    "    loc = b[0] + scale*(gamma(1 + shape) - 1) / shape\n",
    "    ge = genextreme(shape, loc=loc, scale=scale)\n",
    "    \n",
    "    # Get the MLE\n",
    "    def f(par):\n",
    "        shape, loc, logscale = par\n",
    "        d = genextreme(shape, loc=loc, scale=np.exp(logscale))\n",
    "        return -d.logpdf(x).sum()\n",
    "\n",
    "    logscale = np.log(scale)\n",
    "    x0 = np.asarray([shape, loc, logscale])\n",
    "    rr = minimize(f, x0, method=\"powell\")\n",
    "    shape, loc, logscale = rr.x\n",
    "    ge = genextreme(shape, loc=loc, scale=np.exp(logscale))\n",
    "    return ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def block_max(dx):\n",
    "    \"\"\"\n",
    "    Calculate the maximum precipitation value for each complete year,\n",
    "    and fit a generalized extreme value (GEV) distribution to the\n",
    "    data.  Then use the fitted model to calculate returns for a sequence\n",
    "    of time horizons, and create a QQ plot to assess goodness-of-fit.\n",
    "    \n",
    "    Returns the fitted generalized extreme value distribution model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the annual maximum for all complete years\n",
    "    dx = dx.query(\"year > 1958 & year < 2023\")\n",
    "    yrmx = dx.groupby(\"year\")[\"PRCP\"].agg(np.max)\n",
    "    \n",
    "    # Fit a generalized extreme value distribution to the block maxima.\n",
    "    gev = fit_gev(yrmx)\n",
    "\n",
    "    # m-observation returns\n",
    "    rr = pd.DataFrame({\"Years\": [10, 100, 500, 1000]})\n",
    "    rr[\"Return\"] = gev.ppf(1 - 1/rr.Years)\n",
    "    print(rr)\n",
    "\n",
    "    # Make a QQ plot to assess goodness of fit of the GEV model\n",
    "    z = np.sort(yrmx)\n",
    "    n = len(z)\n",
    "    pp = np.arange(1, n + 1) / (n + 1)\n",
    "    qq = gev.ppf(pp)\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.plot(qq, z)\n",
    "    ax.set_xlabel(\"GEV quantiles\")\n",
    "    ax.set_ylabel(\"Order statistics\")\n",
    "    ax.set_title(\"GEV fit to annual maxima\")\n",
    "    plt.show()\n",
    "\n",
    "    return gev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def gp_estimate(z):\n",
    "    \"\"\"\n",
    "    Estimate the parameters of a generalized Pareto distribution\n",
    "    using the empirical Bayes method of Zhang and Stephens.\n",
    "    https://www.jstor.org/stable/pdf/40586625.pdf\n",
    "    \n",
    "    Returns the fitted generalized Pareto model. See the link below for\n",
    "    details about how the distribution is parameterized:\n",
    "    \n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genpareto.html\n",
    "    \"\"\"\n",
    "\n",
    "    # The prior is discrete and data-adaptive, based on these parameters\n",
    "    z = np.sort(z)\n",
    "    n = len(z)\n",
    "    xstar = z[int(np.round(n/4 + 0.5))]\n",
    "    m = np.ceil(20 + np.sqrt(n))\n",
    "    xmax = z.max()\n",
    "\n",
    "    # The grid on which the prior is supported\n",
    "    jj = np.arange(1, m+1)\n",
    "    tgrid = 1/xmax + (1 - np.sqrt(m/(jj-0.5))) / (3 * xstar)\n",
    "\n",
    "    # The profile log likelihood function\n",
    "    def profile(theta):\n",
    "        k = -np.log(1 - theta*z).mean()\n",
    "        return n*(np.log(theta/k) + k - 1)\n",
    "\n",
    "    # The posterior distribution\n",
    "    ltg = np.asarray([profile(t) for t in tgrid])\n",
    "    ltg -= ltg.max()\n",
    "    Ltg = np.exp(ltg)\n",
    "    Ltg /= Ltg.sum()\n",
    "    \n",
    "    # The posterior is a generalized Pareto with these parameters\n",
    "    theta_hat = np.dot(Ltg, tgrid)\n",
    "    k_hat = -np.log(1 - theta_hat*z).mean()\n",
    "    scale_hat = k_hat / theta_hat\n",
    "\n",
    "    # Return the posterior distribution\n",
    "    return genpareto(-k_hat, scale=scale_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eb_analysis(z, thresh):\n",
    "    \"\"\"\n",
    "    Fit a generalized Pareto model to the exceedances derived from z,\n",
    "    using empirical Bayes estimation, and create a QQ plot to assess\n",
    "    the goodness-of-fit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Exceedances\n",
    "    z = z[z > thresh] - thresh\n",
    "\n",
    "    # Empirical Bayes estimate of Zhang and Stephens.\n",
    "    eb = gp_estimate(z)\n",
    "\n",
    "    n = len(z)\n",
    "    pp = np.linspace(1/2, n - 1/2, n) / n # plotting positions\n",
    "    qq = eb.ppf(pp)\n",
    "    z = np.sort(z)\n",
    "\n",
    "    # QQ plot to show goodness of fit\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.set_title(\"EB: shape=%.3f scale=%.3f, tail=%.2f\" % (eb.args[0], eb.kwds[\"scale\"], 1/eb.args[0]))\n",
    "    ax.plot(qq, z)\n",
    "    plt.xlabel(\"GP quantiles (EB)\", size=16)\n",
    "    plt.ylabel(\"Order statistics\", size=16)\n",
    "    plt.show()\n",
    "\n",
    "    return eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_tails(z, p0, thresh, family):\n",
    "    \"\"\"\n",
    "    Plot the tail of the estimated CDF based on the upper 'p0' proportion of the data in z.  \n",
    "    If family is 'exponential' use a semi-log plot, if family is 'powerlaw' use a log/log plot.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # The number of selected observations\n",
    "    m = int(np.around(p0*n))\n",
    "\n",
    "    xlabel = \"log Q(p)\" if family == \"powerlaw\" else \"Q(p)\"\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    icept, alpha = fit_tail_reg(z, ax, p0=p0, family=family)\n",
    "    ax.set_xlabel(xlabel, size=16)\n",
    "    ax.set_ylabel(\"log(1-p)\", size=16)\n",
    "    ti = \"%s model, threshold=%.1f, top %.1f%% (n=%d), alpha=%.3f\" %\\\n",
    "           (family.title(), thresh, 100*p0, m, alpha)\n",
    "    plt.title(ti)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def check_gp_estimate(shape, scale, thresh, n=100000):\n",
    "    z = genpareto.rvs(shape, scale=scale, size=n)\n",
    "    z = z[z > thresh] - thresh\n",
    "    eb = gp_estimate(z)\n",
    "    return eb, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mobs_return(z, mr, thresh, family=\"exponential\", gp=None):\n",
    "    \"\"\"\n",
    "    Calculate the m-observation returns for the data in z, using either\n",
    "    an exponential or generalized Pareto model.\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.asarray(z)\n",
    "    n = len(z)\n",
    "\n",
    "    # Select only extreme values and translate back to the origin\n",
    "    ix = np.flatnonzero(z >= thresh)\n",
    "    q = len(ix) / n # proportion of values exceeding the threshold\n",
    "    z = z[ix]\n",
    "    z -= thresh\n",
    "\n",
    "    pr = 1 - 1 / (q * mr)\n",
    "\n",
    "    if family == \"exponential\":\n",
    "        mn = z.mean()\n",
    "        print(\"Mean = %.2f\" % mn)\n",
    "        m0 = thresh - mn*np.log(1 - pr)\n",
    "    elif family == \"generalizedpareto\":\n",
    "        print(\"Shape=%.2f\" % eb.args[0])\n",
    "        print(\"Scale=%.2f\" % eb.kwds[\"scale\"])\n",
    "        m0 = thresh + gp.ppf(pr)\n",
    "    else:\n",
    "        raise ValueError(\"!!\")\n",
    "\n",
    "    return m0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Change this to point to the location of the data, matching the path name in get_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = Path(\"/home/kshedden/data/Teaching/precip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Choose a specific location to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"USW00094847.csv\" # Detroit\n",
    "#fname = \"USW00012839.csv\" # Miami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(target_dir / (\"%s.gz\" % fname), parse_dates=[\"DATE\"],\n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We only care about these two variables, which must not be missing.  \"PRCP\" is the 24-hour rainfall total, recorded in tenths of a millimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"DATE\", \"PRCP\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Add a year variable for block-maxima (GEV) analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df[\"DATE\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Convert precipitation to millimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PRCP\"] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The data may be sorted already, but sort again just to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"DATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Display the first few rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Use this threshold (units are mm) for calculating exceedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 10.0\n",
    "(df[\"PRCP\"] >= thresh).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Plot the data as a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.plot(df[\"DATE\"], df[\"PRCP\"], \"-\", alpha=0.5)\n",
    "plt.xlabel(\"Date\", size=15)\n",
    "plt.ylabel(\"Precipitation (mm)\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Plot the data as a histogram.  A histogram is not useful for studying extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.hist(df[\"PRCP\"])\n",
    "plt.xlabel(\"Precipitation (mm)\", size=13)\n",
    "plt.ylabel(\"Frequency\", size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Plot the data as an (empirical) CDF.  This is not a very helpful approach for judging the structure of the tail of a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "x = np.sort(df[\"PRCP\"])\n",
    "p = np.linspace(0, 1, len(x))\n",
    "plt.plot(x, p, \"-\")\n",
    "plt.xlabel(\"Precipitation (mm)\", size=15)\n",
    "plt.ylabel(\"Cumulative probability\", size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Plot the data as an (empirical) complementary CDF (also known as the ccdf or survival function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.grid(True)\n",
    "x = np.sort(df[\"PRCP\"])\n",
    "p = np.linspace(0, 1, len(x))\n",
    "plt.plot(x, 1 - p, \"-\")\n",
    "plt.xlabel(\"Precipitation (mm)\", size=15)\n",
    "plt.ylabel(\"Complementary cumulative probability\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Below we generate probability tail plots, assessing goodness of fit of the upper order statistics to either a powerlaw or exponential pattern.  Various upper fractions of the order statistics are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in [\"powerlaw\", \"exponential\"]:\n",
    "    for p0 in [0.25, 0.1, 0.05, 0.01]:\n",
    "        plot_tails(df[\"PRCP\"], p0, thresh, family)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Below is a \"Hill plot\" suggesting that the tail index might be around 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hill(df[\"PRCP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Next we fit generalized extreme value distributions to the block (annual) maxima.  The m-returns based on the GEV model are printed and a qq-plot showing the goodness of fit of the GEV to the data is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gev = block_max(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Below is the shape parameter of the best-fitting GEV to the block maxima.  Due to the parameterization of the GEV used by Scipy, the tail index is -1/shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gev.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "-1/gev.args[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Fit generalized Pareto models to the exceedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = eb_analysis(df[\"PRCP\"], thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Next we calculate m-observation returns based on an exponential and a generalized Pareto model fit to the 24 hour rainfall totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = np.r_[1, 10, 100, 500, 1000]\n",
    "cfg = [(\"exponential\", None), (\"generalizedpareto\", eb)]\n",
    "for (f,g) in cfg:\n",
    "    print(\"\\nReturns based on %s:\" % f)\n",
    "    mr = mobs_return(df[\"PRCP\"], 365 * yr, thresh, family=f, gp=g)\n",
    "    rr = pd.DataFrame({\"Years\": yr, \"MR\": mr})\n",
    "    print(rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "The cell below is a simple demonstration of how to use the gp_estimate function defined above.  Note that there are different parameterizations of the generalized Pareto distribution (this is true of many probability distributions).  Since we are using [scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genpareto.html), here we use the parameterization adopted by scipy, which is also the parameterization shown on [wikipedia](https://en.wikipedia.org/wiki/Generalized_Pareto_distribution).  The shape parameter $\\xi$ is the reciprocal of the tail index $\\alpha$, i.e. $\\alpha = 1/\\xi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1/3.\n",
    "scale = 1\n",
    "\n",
    "# Generate data and obtain an estimated GPD using the empirical Bayes approach.\n",
    "eb, z = check_gp_estimate(shape=shape, scale=scale, thresh=0)\n",
    "\n",
    "# Check that the population and sample medians match (if they don't something is wrong)\n",
    "print(\"Sample median =\", np.median(z))\n",
    "print(\"Population median =\", scale*(2**shape - 1) / shape)\n",
    "\n",
    "# The fitted GPD has this shape parameter\n",
    "print(\"Fitted GPD shape parameter: \", eb.args)\n",
    "\n",
    "# This is the estimated tail index\n",
    "print(\"Estimated tail index: \", 1 / eb.args[0])\n",
    "print(\"Population tail index: \", 1 / shape)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
